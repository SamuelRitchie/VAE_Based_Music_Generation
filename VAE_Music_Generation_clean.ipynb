{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<head>\n",
    "<h1 style=\"text-align:right\"> *Techniques Avancées d'Apprentissage - ENSAE ParisTech - 2017/2018*</h1>  \n",
    "<h1 style=\"text-align:center\">Charles Dognin - Samuel Ritchie</h1>\n",
    "<h3 style=\"text-align:center\"><span style=\"color: #fb4141\">Music and Image generation with Variational Auto-Encoders</span></h3> \n",
    "</head>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook aims at trying to generate music (and in a first time images) thanks to a particular type of generative model : Variational Auto-Encoders. This method was first described by Diederik P. Kingma and Max Welling in *Auto-Encoding Variational Bayes* (https://arxiv.org/pdf/1312.6114.pdf) and today achieves state of the art results along with Generative Adversarial Networks (GANs) in data generation (text, image, music)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import useful packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
       "<script>\n",
       "function repeat_indent_string(n){\n",
       "    var a = \"\" ;\n",
       "    for ( ; n > 0 ; --n)\n",
       "        a += \"    \";\n",
       "    return a;\n",
       "}\n",
       "// look up into all sections and builds an automated menu //\n",
       "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
       "    var anchors = document.getElementsByClassName(\"section\");\n",
       "    if (anchors.length == 0) {\n",
       "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
       "    }\n",
       "    var i,t;\n",
       "    var text_menu = begin;\n",
       "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
       "    var ind = \"\";\n",
       "    var memo_level = 1;\n",
       "    var href;\n",
       "    var tags = [];\n",
       "    var main_item = 0;\n",
       "    var format_open = 0;\n",
       "    for (i = 0; i <= llast; i++)\n",
       "        tags.push(\"h\" + i);\n",
       "\n",
       "    for (i = 0; i < anchors.length; i++) {\n",
       "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
       "\n",
       "        var child = null;\n",
       "        for(t = 0; t < tags.length; t++) {\n",
       "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
       "            if (r.length > 0) {\n",
       "child = r[0];\n",
       "break;\n",
       "            }\n",
       "        }\n",
       "        if (child == null) {\n",
       "            text_memo += \"null\\n\";\n",
       "            continue;\n",
       "        }\n",
       "        if (anchors[i].hasAttribute(\"id\")) {\n",
       "            // when converted in RST\n",
       "            href = anchors[i].id;\n",
       "            text_memo += \"#1-\" + href;\n",
       "            // passer à child suivant (le chercher)\n",
       "        }\n",
       "        else if (child.hasAttribute(\"id\")) {\n",
       "            // in a notebook\n",
       "            href = child.id;\n",
       "            text_memo += \"#2-\" + href;\n",
       "        }\n",
       "        else {\n",
       "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
       "            continue;\n",
       "        }\n",
       "        var title = child.textContent;\n",
       "        var level = parseInt(child.tagName.substring(1,2));\n",
       "\n",
       "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
       "\n",
       "        if ((level < lfirst) || (level > llast)) {\n",
       "            continue ;\n",
       "        }\n",
       "        if (title.endsWith('¶')) {\n",
       "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
       "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
       "        }\n",
       "        if (title.length == 0) {\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        while (level < memo_level) {\n",
       "            text_menu += end_format + \"</ul>\\n\";\n",
       "            format_open -= 1;\n",
       "            memo_level -= 1;\n",
       "        }\n",
       "        if (level == lfirst) {\n",
       "            main_item += 1;\n",
       "        }\n",
       "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
       "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
       "            continue;\n",
       "        }\n",
       "        while (level > memo_level) {\n",
       "            text_menu += \"<ul>\\n\";\n",
       "            memo_level += 1;\n",
       "        }\n",
       "        text_menu += repeat_indent_string(level-2);\n",
       "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
       "        format_open += 1;\n",
       "    }\n",
       "    while (1 < memo_level) {\n",
       "        text_menu += end_format + \"</ul>\\n\";\n",
       "        memo_level -= 1;\n",
       "        format_open -= 1;\n",
       "    }\n",
       "    text_menu += send;\n",
       "    //text_menu += \"\\n\" + text_memo;\n",
       "\n",
       "    while (format_open > 0) {\n",
       "        text_menu += end_format;\n",
       "        format_open -= 1;\n",
       "    }\n",
       "    return text_menu;\n",
       "};\n",
       "var update_menu = function() {\n",
       "    var sbegin = \"\";\n",
       "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
       "    var send = \"\";\n",
       "    var begin_format = '<li>';\n",
       "    var end_format = '</li>';\n",
       "    var keep_item = -1;\n",
       "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item,\n",
       "       begin_format, end_format);\n",
       "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
       "    menu.innerHTML=text_menu;\n",
       "};\n",
       "window.setTimeout(update_menu,2000);\n",
       "            </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import IPython\n",
    "from keras import metrics\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, History\n",
    "import numpy as np\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import LSTM, Dense, Embedding, Bidirectional, Dropout, Conv1D, \\\n",
    "    MaxPooling1D, Flatten, BatchNormalization, LeakyReLU, Lambda\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.engine.topology import Input\n",
    "from keras import backend as K\n",
    "from IPython.display import Image\n",
    "import cv2\n",
    "from scipy.io import wavfile\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from jyquickhelper import add_notebook_menu\n",
    "add_notebook_menu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Keras with associated Tensorflow backend and relevant associated functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. A few theoretical aspects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by giving a few insights on generative models and VAEs. Please refer to the full report in /Deliverables folder for more details.\n",
    "\n",
    "Basically, a generative model comes down to describing how data is generated in terms of probabilistic model. Two of the most commonly used and efficient approaches are VAEs and GANs. These both methods fundamentally differ in the approach for density estimation : GANs aims at achieving a Nash equilibrium between a Generator and a Discriminator, while VAEs are based on the auto-encoder theory.\n",
    "\n",
    "Traditional Auto-Encoders are models whose goal are to learn a compressed representation of the data, similarly to the Principal Component Analysis. The autoencoder has two parts: an encoder and a decoder. The encoder encodes the input into a \"code\" (also called latent space), generally of lower dimension than the input in order to only keep the most important information. While the primary purpose of such models was dimensionality reduction, the rise of deep learning frameworks and interest in generating data made the autoencoder concept be widely used for learning generative models of data.\n",
    "\n",
    "<img src=\"images/autoencoder.jpg\" >\n",
    "<figcaption>*Image source : https://blog.keras.io/building-autoencoders-in-keras.html*</figcaption>\n",
    "\n",
    "Many applications use autoencoder methods, among which dimensionality reduction as already mentioned, and most importantly denoising autoencoders allowing to find the relevant features in a blurred input signal. However, regarding generation of data from the learned representation, they are extremely limited. Indeed, the latent variable does not have a tractable distribution, or said in other terms the latent space may not allow easy interpolation. More precisely, one could say that autoencoders are fine for *replicating* data (thanks to clusters in the latent space), but is not good at *generating* new data because of eventual discontinuities in the latent space, as it can be seen in the following image.\n",
    "\n",
    "Let x be the data we want to model and z the latent variable (in a lower dimension). In what follows, we will refer to the decoder network distribution modeling as $p_{\\theta}(x|z)$ and the encoder one as $q_{\\Phi}(z|x)$. Our goal is to learn model parameters in order to maximize the likelihood of training data :\n",
    "\n",
    "$$ p_{\\theta} (x) = \\int p_{\\theta} (z) p_{\\theta} (x|z) dz$$\n",
    "\n",
    "This problem is completely untractable since it is impossible to integrate over the whole latent space. Using variational inference methods (see report for details), one can lower bound the log-likelihood by a sum of two terms :\n",
    "\n",
    "$$ \n",
    "\\log p_{\\theta}(x) \\geq \\mathcal{L}(x, \\theta, \\Phi) = \\mathbb{E}_z \\left[ \\log p_{\\theta}(x|z) \\right] - D_{KL} \\left( q_{\\Phi}(z|x), p_{\\theta}(z)\\right) \\\\\n",
    " $$\n",
    "\n",
    "The variational lower-bound is the sum of two terms (in the auto-encoder we only had reconstruction loss) : \n",
    "> -  the *reconstruction error* : it is the log-likelihood of the observed $x$ given the latent feature $z$ we have sampled. It is linked to the decoder network performances $p_{x|z}$ \n",
    "> -  the second part corresponds to the difference between distributions $p(z)$ we want to estimate and $q(z|x)$ which is used to approximate it. In practice, standard normal distributions will be used. This part checks that the proposal distribution should be like a Gaussian (or any other chosen distribution) and is often called the *regularization term*\n",
    "\n",
    "<img src=\"images/latent_space_diff.png\" >\n",
    "<figcaption>*Image source : https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf*</figcaption>\n",
    "\n",
    "The image above clearly shows to what extent VAEs enable us to sample new image from the latent space, and not only replicate data as auto-encoders do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. VAE Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Signal Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Image pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data imports and processing\n",
    "\n",
    "x_train_img, x_val_img = [], []\n",
    "p_train = Path(\"data/train\")\n",
    "p_val = Path(\"data/val\")\n",
    "data_train = list(p_train.glob(\"*.jpg\"))\n",
    "data_val = list(p_val.glob(\"*.jpg\"))\n",
    "data_train = [str(path) for path in data_train]\n",
    "data_val = [str(path) for path in data_val]\n",
    "\n",
    "for path in data_train:\n",
    "    im = cv2.imread(path)\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    im = im.astype('float32')\n",
    "    im = cv2.resize(im, (70, 70)) / 255\n",
    "    im = np.expand_dims(im, axis=0)\n",
    "    x_train_img.append(im)\n",
    "    \n",
    "for path in data_val:\n",
    "    im = cv2.imread(path)\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    im = im.astype('float32')\n",
    "    im = cv2.resize(im, (70, 70)) / 255\n",
    "    im = np.expand_dims(im, axis=0)\n",
    "    x_val_img.append(im)\n",
    "\n",
    "x_train_img = np.array(x_train_img)\n",
    "x_train_img = x_train.reshape((len(x_train_img), np.prod(x_train_img.shape[1:])))\n",
    "\n",
    "x_val_img = np.array(x_val_img)\n",
    "x_val_img = x_val.reshape((len(x_val_img), np.prod(x_val_img.shape[1:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Audio pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlesdognin/anaconda3/lib/python3.6/site-packages/scipy/io/wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    }
   ],
   "source": [
    "x_train_mus =[]\n",
    "for filename in os.listdir('data/music_train/'):\n",
    "\n",
    "    if len(wavfile.read('data/music_train/%s' % filename)[1].shape) == 1:\n",
    "        data = wavfile.read('data/music_train/%s' % filename)[1]\n",
    "        rate = wavfile.read('data/music_train/%s' % filename)[0]\n",
    "        cut_data = data[:10000]\n",
    "        x_train_mus.append(cut_data)\n",
    "        #wavfile.write('data/temp/temp_%s' % filename, rate, cut_data)\n",
    "x_train_mus = np.array(x_train_mus)\n",
    "x_val_mus = x_train[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Training algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_47 (InputLayer)           (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mlp_encoder (Model)             [(None, 10), (None,  10021020    input_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "latent_sampler (Lambda)         (None, 10)           0           mlp_encoder[1][0]                \n",
      "                                                                 mlp_encoder[1][1]                \n",
      "__________________________________________________________________________________________________\n",
      "mlp_decoder (Model)             (None, 10000)        10021000    latent_sampler[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 20,042,020\n",
      "Trainable params: 20,042,020\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlesdognin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:153: UserWarning: Output \"mlp_decoder\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"mlp_decoder\" during training.\n"
     ]
    }
   ],
   "source": [
    "# Essayer différentes activations, différentes profondeurs, différents types de couches\n",
    "\n",
    "class VAE:\n",
    "    \"\"\"\n",
    "    Variational Auto-Encoder class taking as input the training and validation musics or images, as well as the \n",
    "    size of the original, intermediate and latent dim, batch_size and epochs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x_train, x_val, batch_size, epochs, original_dim=10000, \n",
    "                 latent_dim=10, intermediate_dim=1000):\n",
    "        self.x_train = x_train\n",
    "        self.x_val = x_val\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.original_dim = original_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.intermediate_dim = intermediate_dim\n",
    "        self.encoder = self.make_encoder()\n",
    "        self.sampling_layer = self.make_sampling_layer()\n",
    "        self.decoder = self.make_decoder()\n",
    "        self.vae_model = self.make_vae(self.sampling_layer, self.encoder, self.decoder)\n",
    "               \n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        Train the Vae using the Adam Optimizer. \n",
    "        \"\"\"\n",
    "        \n",
    "        self.vae_model.fit(self.x_train,\n",
    "                           epochs=self.epochs,\n",
    "                           batch_size=self.batch_size,\n",
    "                           validation_data=(self.x_val, None),)\n",
    "        \n",
    "    def predict(self, z_test):\n",
    "        \"\"\"\n",
    "        At test time, we evaluate the VAE's ability to generate a new sample. We can remove the \n",
    "        encoder as there is no test image. We sample z from a N(0, I), pass it through the decoder.\n",
    "        There are no good quantitative metrics, only visual appreciation.\n",
    "        \n",
    "        Arguments:\n",
    "        z_test -- sample from the standard Gaussian distribution to which we apply the trained decoder\n",
    "        \n",
    "        Returns:\n",
    "        pred -- the generated image or music\n",
    "        \"\"\"\n",
    "        \n",
    "        pred = self.decoder.predict(z_test)\n",
    "        \n",
    "        return pred\n",
    "     \n",
    "    def make_encoder(self):\n",
    "        \"\"\"\n",
    "        Transform the input into a distribution, composed of the mean and the variance\n",
    "        \n",
    "        Returns:\n",
    "        model -- the encoder model with the object as input and the z_mean and z_sigma \n",
    "        as output\n",
    "        \"\"\"\n",
    "        \n",
    "        enc_input = Input(shape=(self.original_dim,)) # The original image or sound\n",
    "        # First fully connected layer with a rectified linear unit activation function to only keep the positive parts\n",
    "        # of the neurons the size is already reduced to intermediate_dim\n",
    "        x = Dense(self.intermediate_dim, activation='relu')(enc_input) \n",
    "        # Twins fully connected layers determining the mean and the variance of the latent distribution\n",
    "        # of the neurons, the size is further reduced to latent dim\n",
    "        self.z_mean = Dense(self.latent_dim)(x)\n",
    "        self.z_sigma = Dense(self.latent_dim)(x)\n",
    "        model = Model(enc_input, outputs = [self.z_mean, self.z_sigma], name=\"mlp_encoder\")\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def make_decoder(self):\n",
    "        \"\"\"\n",
    "        Decodes the latent vector z and match it with the original output\n",
    "        \n",
    "        Returns:\n",
    "        model -- the decoder model with the latent variable as input and the original object as output\n",
    "        \"\"\"\n",
    "        \n",
    "        dec_input = Input(shape=(self.latent_dim,)) # The input is the latent distribution\n",
    "        x = Dense(self.intermediate_dim, activation='relu')(dec_input) # First fully connected to decode \n",
    "        x = Dense(self.original_dim, activation='sigmoid')(x) # Second fully connected with sigmoid activation\n",
    "        model = Model(dec_input, x, name=\"mlp_decoder\")\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def sampling(self, params):\n",
    "        \"\"\"\n",
    "        Function that uses the learned mean and sigma from the data and return the latent vector z\n",
    "        This is the re-parametrization trick. Instead of taking (z -> N(z_mean, z_sigma)), we take\n",
    "        (epsilon -> N(0, I) and z = z_mean + z_sigma * epsilon). \n",
    "        \n",
    "        Arguments:\n",
    "        z_mean -- the learned mean\n",
    "        z_sigma -- the learned standard deviation\n",
    "        \n",
    "        Returns:\n",
    "        z -- the latent generated distribution (vector of dimension latent_dim)\n",
    "        \"\"\"\n",
    "        \n",
    "        z_mean, z_sigma = params \n",
    "        epsilon = K.random_normal((self.batch_size, self.latent_dim), 0.0, 1.0) # Epsilon is the random part following\n",
    "        # a standard Gaussian distribution\n",
    "        z = z_mean + K.exp(z_sigma / 2) * epsilon # We use the reparametrization trick to make the function \n",
    "        # differentiable to be able to apply back-propagation\n",
    "\n",
    "        return z\n",
    "        \n",
    "    def make_sampling_layer(self):\n",
    "        \"\"\"\n",
    "        Make the sampling layer using the Lambda function from Keras which can transform any function to a \n",
    "        layer type for compatibility with the rest of the network.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create a layer composed which will take as arguments the learned mean and variance and will output\n",
    "        # the latent distribution z \n",
    "        sampling_layer = Lambda(self.sampling, output_shape=(self.latent_dim,), name=\"latent_sampler\")\n",
    "        return sampling_layer\n",
    "    \n",
    "    def make_vae(self, sampling_layer, encoder, decoder):\n",
    "        \"\"\"\n",
    "        Compile the entire variational auto-encoder\n",
    "        \n",
    "        Arguments:\n",
    "        sampling_layer -- the sampling layer transforming the mean and the variance into an approximate Gaussian \n",
    "        distribution\n",
    "        encoder -- the encoder model taking the input and outputing the mean and the variance\n",
    "        decoder -- the decoder model taking the generated latent distribution z as input and outputing the decoded\n",
    "        input\n",
    "        \n",
    "        Returns:\n",
    "        vae_model -- the compiled vae_model, using adam optimizer and the custom loss composed of the cross entropy loss\n",
    "        and the Kullback–Leibler divergence loss\n",
    "        \"\"\"\n",
    "        \n",
    "        input_ = Input(shape=(self.original_dim,)) # the original image/music\n",
    "        z_mean, z_sigma = encoder(input_) # the learned mean and variance of the input\n",
    "        z = sampling_layer([z_mean, z_sigma]) # the learned latent distribution from the input\n",
    "        x_decoded = decoder(z) # the decoded input\n",
    "        vae_model = Model(input_, x_decoded, name=\"vae_mlp\") \n",
    "        \n",
    "        ## Loss ##\n",
    "        \n",
    "        xent_loss = self.original_dim * metrics.binary_crossentropy(\n",
    "        K.flatten(input_), K.flatten(x_decoded)) # the classical binary cross-entropy loss between the input and the \n",
    "        # reconstructed input\n",
    "        \n",
    "        kl_loss = - 0.5 * K.sum(1 + z_sigma - K.square(z_mean) - K.exp(z_sigma), axis=-1) # the kullback-leibler based loss\n",
    "        # which compels the latent distribution to be close to a Gaussian distribution\n",
    "        vae_loss = K.mean(xent_loss + kl_loss) # We take the average of the 2 losses \n",
    "        vae_model.add_loss(vae_loss)\n",
    "        \n",
    "        ## Now that we have the loss and the optimizer we can compile\n",
    "        vae_model.compile(optimizer='adam')\n",
    "        vae_model.summary()\n",
    "    \n",
    "        return vae_model\n",
    "    \n",
    "    \n",
    "vae = VAE(x_train_mus, x_val_mus, 1, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4 samples, validate on 2 samples\n",
      "Epoch 1/15\n",
      "4/4 [==============================] - 3s 654ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/15\n",
      "4/4 [==============================] - 1s 183ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/15\n",
      "4/4 [==============================] - 1s 187ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/15\n",
      "4/4 [==============================] - 1s 184ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/15\n",
      "4/4 [==============================] - 1s 178ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/15\n",
      "4/4 [==============================] - 1s 179ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/15\n",
      "4/4 [==============================] - 1s 179ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/15\n",
      "4/4 [==============================] - 1s 180ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/15\n",
      "4/4 [==============================] - 1s 183ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/15\n",
      "4/4 [==============================] - 1s 197ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/15\n",
      "4/4 [==============================] - 1s 187ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/15\n",
      "4/4 [==============================] - 1s 192ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/15\n",
      "4/4 [==============================] - 1s 180ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/15\n",
      "4/4 [==============================] - 1s 188ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/15\n",
      "4/4 [==============================] - 1s 200ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected input_43 to have shape (10,) but got array with shape (1000,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-77a25170d859>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mz_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-51-2b8ec23da72d>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, z_test)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \"\"\"\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1815\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1816\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1817\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1818\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1819\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    121\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : expected input_43 to have shape (10,) but got array with shape (1000,)"
     ]
    }
   ],
   "source": [
    "vae.fit()\n",
    "z_test = np.random.randn(10,1000)\n",
    "pred = vae.predict(z_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
