{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <p style=\"text-align:right\";> *Techniques Avancées d'Apprentissage - ENSAE ParisTech - 2017/2018*</p>  <p style=\"text-align:right\";>Charles Dognin - Samuel Ritchie</p>\n",
    "\n",
    "# <p style=\"text-align:center\";><span style=\"color: #fb4141\">Music generation with Variational Auto-Encoders</span></p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook aims at trying to generate music (and in a first time images) thanks to a particular type of generative model : Variational Auto-Encoders. This method was first described by Diederik P. Kingma and Max Welling in *Auto-Encoding Variational Bayes* (https://arxiv.org/pdf/1312.6114.pdf) and today achieves state of the art results along with Generative Adversarial Networks (GANs) in data generation (text, image, music)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import useful packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
       "<script>\n",
       "function repeat_indent_string(n){\n",
       "    var a = \"\" ;\n",
       "    for ( ; n > 0 ; --n)\n",
       "        a += \"    \";\n",
       "    return a;\n",
       "}\n",
       "// look up into all sections and builds an automated menu //\n",
       "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
       "    var anchors = document.getElementsByClassName(\"section\");\n",
       "    if (anchors.length == 0) {\n",
       "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
       "    }\n",
       "    var i,t;\n",
       "    var text_menu = begin;\n",
       "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
       "    var ind = \"\";\n",
       "    var memo_level = 1;\n",
       "    var href;\n",
       "    var tags = [];\n",
       "    var main_item = 0;\n",
       "    var format_open = 0;\n",
       "    for (i = 0; i <= llast; i++)\n",
       "        tags.push(\"h\" + i);\n",
       "\n",
       "    for (i = 0; i < anchors.length; i++) {\n",
       "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
       "\n",
       "        var child = null;\n",
       "        for(t = 0; t < tags.length; t++) {\n",
       "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
       "            if (r.length > 0) {\n",
       "child = r[0];\n",
       "break;\n",
       "            }\n",
       "        }\n",
       "        if (child == null) {\n",
       "            text_memo += \"null\\n\";\n",
       "            continue;\n",
       "        }\n",
       "        if (anchors[i].hasAttribute(\"id\")) {\n",
       "            // when converted in RST\n",
       "            href = anchors[i].id;\n",
       "            text_memo += \"#1-\" + href;\n",
       "            // passer à child suivant (le chercher)\n",
       "        }\n",
       "        else if (child.hasAttribute(\"id\")) {\n",
       "            // in a notebook\n",
       "            href = child.id;\n",
       "            text_memo += \"#2-\" + href;\n",
       "        }\n",
       "        else {\n",
       "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
       "            continue;\n",
       "        }\n",
       "        var title = child.textContent;\n",
       "        var level = parseInt(child.tagName.substring(1,2));\n",
       "\n",
       "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
       "\n",
       "        if ((level < lfirst) || (level > llast)) {\n",
       "            continue ;\n",
       "        }\n",
       "        if (title.endsWith('¶')) {\n",
       "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
       "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
       "        }\n",
       "        if (title.length == 0) {\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        while (level < memo_level) {\n",
       "            text_menu += end_format + \"</ul>\\n\";\n",
       "            format_open -= 1;\n",
       "            memo_level -= 1;\n",
       "        }\n",
       "        if (level == lfirst) {\n",
       "            main_item += 1;\n",
       "        }\n",
       "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
       "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
       "            continue;\n",
       "        }\n",
       "        while (level > memo_level) {\n",
       "            text_menu += \"<ul>\\n\";\n",
       "            memo_level += 1;\n",
       "        }\n",
       "        text_menu += repeat_indent_string(level-2);\n",
       "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
       "        format_open += 1;\n",
       "    }\n",
       "    while (1 < memo_level) {\n",
       "        text_menu += end_format + \"</ul>\\n\";\n",
       "        memo_level -= 1;\n",
       "        format_open -= 1;\n",
       "    }\n",
       "    text_menu += send;\n",
       "    //text_menu += \"\\n\" + text_memo;\n",
       "\n",
       "    while (format_open > 0) {\n",
       "        text_menu += end_format;\n",
       "        format_open -= 1;\n",
       "    }\n",
       "    return text_menu;\n",
       "};\n",
       "var update_menu = function() {\n",
       "    var sbegin = \"\";\n",
       "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
       "    var send = \"\";\n",
       "    var begin_format = '<li>';\n",
       "    var end_format = '</li>';\n",
       "    var keep_item = -1;\n",
       "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item,\n",
       "       begin_format, end_format);\n",
       "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
       "    menu.innerHTML=text_menu;\n",
       "};\n",
       "window.setTimeout(update_menu,2000);\n",
       "            </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import IPython\n",
    "from IPython.display import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from jyquickhelper import add_notebook_menu\n",
    "add_notebook_menu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Keras with associated Tensorflow backend and relevant associated functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import metrics\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, History\n",
    "import numpy as np\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import LSTM, Dense, Embedding, Bidirectional, Dropout, Conv1D, \\\n",
    "    MaxPooling1D, Flatten, BatchNormalization, LeakyReLU, Lambda\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.engine.topology import Input\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. A few theoretical aspects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by giving a few insights on generative models and VAEs. Please refer to the full report in /Deliverables folder for more details.\n",
    "\n",
    "Basically, a generative model comes down to describing how data is generated in terms of probabilistic model. Two of the most commonly used and efficient approaches are VAEs and GANs. These both methods fundamentally differ in the approach for density estimation : GANs aims at achieving a Nash equilibrium between a Generator and a Discriminator, while VAEs are based on the auto-encoder theory.\n",
    "\n",
    "Traditional Auto-Encoders are models whose goal are to learn a compressed representation of the data, similarly to the Principal Component Analysis. The autoencoder has two parts: an encoder and a decoder. The encoder encodes the input into a \"code\" (also called latent space), generally of lower dimension than the input in order to only keep the most important information. While the primary purpose of such models was dimensionality reduction, the rise of deep learning frameworks and interest in generating data made the autoencoder concept be widely used for learning generative models of data.\n",
    "\n",
    "<img src=\"images/autoencoder.jpg\" >\n",
    "<figcaption>*Image source : https://blog.keras.io/building-autoencoders-in-keras.html*</figcaption>\n",
    "\n",
    "Many applications use autoencoder methods, among which dimensionality reduction as already mentioned, and most importantly denoising autoencoders allowing to find the relevant features in a blurred input signal. However, regarding generation of data from the learned representation, they are extremely limited. Indeed, the latent variable does not have a tractable distribution, or said in other terms the latent space may not allow easy interpolation. More precisely, one could say that autoencoders are fine for *replicating* data (thanks to clusters in the latent space), but is not good at *generating* new data because of eventual discontinuities in the latent space, as it can be seen in the following image.\n",
    "\n",
    "Let x be the data we want to model and z the latent variable (in a lower dimension). In what follows, we will refer to the decoder network distribution modeling as $p_{\\theta}(x|z)$ and the encoder one as $q_{\\Phi}(z|x)$. Our goal is to learn model parameters in order to maximize the likelihood of training data :\n",
    "\n",
    "$$ p_{\\theta} (x) = \\int p_{\\theta} (z) p_{\\theta} (x|z) dz$$\n",
    "\n",
    "This problem is completely untractable since it is impossible to integrate over the whole latent space. Using variational inference methods (see report for details), one can lower bound the log-likelihood by a sum of two terms :\n",
    "\n",
    "$$ \n",
    "\\log p_{\\theta}(x) \\geq \\mathcal{L}(x, \\theta, \\Phi) = \\mathbb{E}_z \\left[ \\log p_{\\theta}(x|z) \\right] - D_{KL} \\left( q_{\\Phi}(z|x), p_{\\theta}(z)\\right) \\\\\n",
    " $$\n",
    "\n",
    "The variational lower-bound is the sum of two terms (in the auto-encoder we only had reconstruction loss) : \n",
    "> -  the *reconstruction error* : it is the log-likelihood of the observed $x$ given the latent feature $z$ we have sampled. It is linked to the decoder network performances $p_{x|z}$ \n",
    "> -  the second part corresponds to the difference between distributions $p(z)$ we want to estimate and $q(z|x)$ which is used to approximate it. In practice, standard normal distributions will be used. This part checks that the proposal distribution should be like a Gaussian (or any other chosen distribution) and is often called the *regularization term*\n",
    "\n",
    "<img src=\"images/latent_space_diff.png\" >\n",
    "<figcaption>*Image source : https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf*</figcaption>\n",
    "\n",
    "The image above clearly shows to what extent VAEs enable us to sample new image from the latent space, and not only replicate data as auto-encoders do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. VAE Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Signal Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Image pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val = [], []\n",
    "p_train = Path(\"data/train\")\n",
    "p_val = Path(\"data/val\")\n",
    "data_train = list(p_train.glob(\"*.jpg\"))\n",
    "data_val = list(p_val.glob(\"*.jpg\"))\n",
    "data_train = [str(path) for path in data_train]\n",
    "data_val = [str(path) for path in data_val]\n",
    "\n",
    "for path in data_train:\n",
    "    im = cv2.imread(path)\n",
    "    im = im.astype('float32')\n",
    "    im = cv2.resize(im, (20, 20)) / 255\n",
    "    im = np.expand_dims(im, axis=0)\n",
    "    x_train.append(im)\n",
    "    \n",
    "for path in data_val:\n",
    "    im = cv2.imread(path)\n",
    "    im = im.astype('float32')\n",
    "    im = cv2.resize(im, (20, 20)) / 255\n",
    "    im = np.expand_dims(im, axis=0)\n",
    "    x_val.append(im)\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "\n",
    "x_val = np.array(x_val)\n",
    "x_val = x_val.reshape((len(x_val), np.prod(x_val.shape[1:])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Audio pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Training algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essayer différentes activations, différentes profondeurs, différents types de couches\n",
    "\n",
    "class VAE:\n",
    "\n",
    "    def __init__(self, batch_size, epochs, original_dim=1200, \n",
    "                 latent_dim=100, intermediate_dim=100):\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.original_dim = original_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.intermediate_dim = intermediate_dim\n",
    "        self.encoder = self.make_encoder()\n",
    "        self.sampling_layer = self.make_sampling_layer()\n",
    "        self.decoder = self.make_decoder()\n",
    "        self.vae_model = self.make_vae(self.sampling_layer, self.encoder, self.decoder)\n",
    "\n",
    "    def fit(self, x_train, x_val):\n",
    "        \"\"\"\n",
    "        Train the Vae using the Adam Optimizer. \n",
    "        \"\"\"\n",
    "        \n",
    "        early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                                       patience=3,\n",
    "                                       mode='min')\n",
    "\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                                      patience=1, min_lr=0.001)\n",
    "        \n",
    "        #xent_loss = self.original_dim * metrics.binary_crossentropy(\n",
    "        #K.flatten(x_train), K.flatten(self.x_decoded))\n",
    "        #kl_loss = - 0.5 * K.sum(1 + self.z_sigma - K.square(self.z_mean) - K.exp(self.z_sigma), axis=-1)\n",
    "        #vae_loss = K.mean(xent_loss + kl_loss)\n",
    "        #self.vae_model.add_loss(vae_loss)\n",
    "        self.vae_model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\")\n",
    "        self.vae_model.fit(x_train, x_train,\n",
    "                           validation_data=(x_val, x_val), \n",
    "                           epochs=self.epochs,\n",
    "                           batch_size=self.batch_size,\n",
    "                           callbacks=[reduce_lr, early_stopping])\n",
    "        \n",
    "    def predict(self, z_test):\n",
    "        \"\"\"\n",
    "        At test time, we evaluate the VAE's ability to generate a new sample. We can remove the \n",
    "        encoder as there is no test image. We sample z from a N(0, I), pass it through the decoder.\n",
    "        There are no good quantitative metrics, only visual appreciation.\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.decoder.predict(z_test)\n",
    "     \n",
    "    def make_encoder(self):\n",
    "        \"\"\"\n",
    "        Transform the input into a distribution, composed of the mean and the variance\n",
    "        \n",
    "        Returns:\n",
    "        model -- the encoder model with the object as input and the z_mean and z_sigma \n",
    "        as output\n",
    "        \"\"\"\n",
    "        \n",
    "        enc_input = Input(shape=(self.original_dim,))\n",
    "        # We can try without the intermediate dim, directly relating input to latent z\n",
    "        x = Dense(self.intermediate_dim, activation='relu')(enc_input)\n",
    "        self.z_mean = Dense(self.latent_dim)(x)\n",
    "        self.z_sigma = Dense(self.latent_dim)(x)\n",
    "        model = Model(enc_input, outputs = [self.z_mean, self.z_sigma])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def make_decoder(self):\n",
    "        \"\"\"\n",
    "        Decodes the latent vector z and match it with the original output\n",
    "        \n",
    "        Returns:\n",
    "        model -- the decoder model with the latent variable as input and the original object as output\n",
    "        \"\"\"\n",
    "        \n",
    "        dec_input = Input(shape=(self.latent_dim,))\n",
    "        x = Dense(self.intermediate_dim, activation='relu')(dec_input)\n",
    "        x = Dense(self.original_dim, activation='sigmoid')(x)\n",
    "        model = Model(dec_input, x)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def sampling(self, params):\n",
    "        \"\"\"\n",
    "        Function that uses the learned mean and sigma from the data and return the latent vector z\n",
    "        This is the re-parametrization trick. Instead of taking (z -> N(z_mean, z_sigma)), we take\n",
    "        (epsilon -> N(0, I) and z = z_mean + z_sigma * epsilon). \n",
    "        Arguments:\n",
    "        z_mean -- the learned mean\n",
    "        z_sigma -- the learned standard deviation\n",
    "        \"\"\"\n",
    "        \n",
    "        z_mean, z_sigma = params\n",
    "        epsilon = K.random_normal((self.batch_size, self.latent_dim), 0.0, 1.0)\n",
    "        z = z_mean + K.exp(z_sigma / 2) * epsilon\n",
    "\n",
    "        return z\n",
    "        \n",
    "    def make_sampling_layer(self):\n",
    "        sampling_layer = Lambda(self.sampling, output_shape=(self.latent_dim,))\n",
    "        return sampling_layer\n",
    "    \n",
    "    def make_vae(self, sampling_layer, encoder, decoder):\n",
    "        \"\"\"\n",
    "        Compile the entire variational auto-encoder\n",
    "        \"\"\"\n",
    "        \n",
    "        input_ = Input(shape=(self.original_dim,))\n",
    "        z_mean, z_sigma = encoder(input_)\n",
    "        z = sampling_layer([z_mean, z_sigma])\n",
    "        self.x_decoded = decoder(z)\n",
    "        model = Model(input_, self.x_decoded)\n",
    "    \n",
    "        return model  \n",
    "    \n",
    "vae = VAE(1, 50)\n",
    "vae.fit(x_train, x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_test = np.random.randn(1,100)\n",
    "pred = vae.predict(z_test)\n",
    "pred = pred.reshape((20, 20, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_train[0].reshape(20, 20, 3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
